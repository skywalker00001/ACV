{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN618RPouFL63HN6WD1SpJI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3452345dff754d3e8ba6fe31675272f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff93615895714479b6b044ef66a08b73",
              "IPY_MODEL_52b8a66fd8034805a5e2e66f3da42f0d",
              "IPY_MODEL_210bc359f4e8457fa8f49d700322cda7"
            ],
            "layout": "IPY_MODEL_1e46c9b7141d42a88c278b6f1009a343"
          }
        },
        "ff93615895714479b6b044ef66a08b73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b9d045c4ccf40f3937d2b0c14c0cf9e",
            "placeholder": "​",
            "style": "IPY_MODEL_5b8ef82de1bd450bb311792025a75da8",
            "value": "100%"
          }
        },
        "52b8a66fd8034805a5e2e66f3da42f0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9edb9b3fb429489590377be30ade89ca",
            "max": 87306240,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38175f951075450cad17e5f856eede78",
            "value": 87306240
          }
        },
        "210bc359f4e8457fa8f49d700322cda7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5133565d83a449df8a25e6281655aa5c",
            "placeholder": "​",
            "style": "IPY_MODEL_c0627c483191408caa378712fab149eb",
            "value": " 83.3M/83.3M [00:01&lt;00:00, 76.1MB/s]"
          }
        },
        "1e46c9b7141d42a88c278b6f1009a343": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b9d045c4ccf40f3937d2b0c14c0cf9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b8ef82de1bd450bb311792025a75da8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9edb9b3fb429489590377be30ade89ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38175f951075450cad17e5f856eede78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5133565d83a449df8a25e6281655aa5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0627c483191408caa378712fab149eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b5aeb77d2f04207a206a09ff37ee6a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4bd1296e69ea4b95bebc93b73fcb3367",
              "IPY_MODEL_93d42be650ed4944ac5dd43568b88eea"
            ],
            "layout": "IPY_MODEL_bb0f528f504d43ebaee5907f66cfb9a5"
          }
        },
        "4bd1296e69ea4b95bebc93b73fcb3367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dae0e11aaae40538823d441cb3b0b35",
            "placeholder": "​",
            "style": "IPY_MODEL_597c7526b38a49ebb2a212330914f383",
            "value": "0.033 MB of 0.033 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "93d42be650ed4944ac5dd43568b88eea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49832372043942d5a821c6e057749438",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_95e3d8d857bb4f2c815af1a8ea390b2a",
            "value": 1
          }
        },
        "bb0f528f504d43ebaee5907f66cfb9a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dae0e11aaae40538823d441cb3b0b35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "597c7526b38a49ebb2a212330914f383": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49832372043942d5a821c6e057749438": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95e3d8d857bb4f2c815af1a8ea390b2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skywalker00001/ACV/blob/main/ultimate_version_of_face_parsing2_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Version2.1"
      ],
      "metadata": {
        "id": "Eg9FYmTVucFE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "pbKVFEytuozV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "ROOT = 'drive/MyDrive/ACV/Project1'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ha1h1YqSy7Ll",
        "outputId": "12e2d0e0-60c9-40d5-abc7-c62b7ad40dad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking out the GPU we have access to. This is output is from the google colab version.\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vf_UbIBd-8PK",
        "outputId": "67c9daf6-85ab-4d3e-9fb3-86eee3ae5db5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Mar 22 22:17:54 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install segmentation_models_pytorch\n",
        "!pip install wandb -qqq\n",
        "import wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GjvC0ODu4Le",
        "outputId": "20c7370a-72d7-4bad-d099-5443af0d97f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: segmentation_models_pytorch in /usr/local/lib/python3.7/dist-packages (0.2.1)\n",
            "Requirement already satisfied: efficientnet-pytorch==0.6.3 in /usr/local/lib/python3.7/dist-packages (from segmentation_models_pytorch) (0.6.3)\n",
            "Requirement already satisfied: timm==0.4.12 in /usr/local/lib/python3.7/dist-packages (from segmentation_models_pytorch) (0.4.12)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from segmentation_models_pytorch) (0.11.1+cu111)\n",
            "Requirement already satisfied: pretrainedmodels==0.7.4 in /usr/local/lib/python3.7/dist-packages (from segmentation_models_pytorch) (0.7.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet-pytorch==0.6.3->segmentation_models_pytorch) (1.10.0+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch) (4.63.0)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet-pytorch==0.6.3->segmentation_models_pytorch) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.21.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from munch->pretrainedmodels==0.7.4->segmentation_models_pytorch) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Login to wandb to log the model run and all the parameters\n",
        "# 7229adacb32965027d73056a6927efd0365a00bc\n",
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnHq35Rpu-Lh",
        "outputId": "29b1ac21-7602-479b-ef67-8aa67f7b0ec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mskywalk3r\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc4LeCMsvBFu",
        "outputId": "2f56060b-bc5b-4df4-ee6b-e081666c38c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mskywalk3r\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8_ZRhDNuZF_"
      },
      "outputs": [],
      "source": [
        "#import wandb\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import time\n",
        "\n",
        "import torch, torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "from torch import cuda\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import segmentation_models_pytorch as smp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Setting up the device for GPU usage\n",
        "\n",
        "DEVICE = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print(\"DEVICE is: \", DEVICE)\n",
        "\n",
        "# Set random seeds and deterministic pytorch for reproducibility\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED) # pytorch random seed\n",
        "np.random.seed(SEED) # numpy random seed\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JosMSrKbxPse",
        "outputId": "7c3307e7-5276-477d-bb6b-8c29f5122202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICE is:  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "EHbrVUb-TP91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy2d(input, target, weight=None, size_average=True):\n",
        "    n, c, h, w = input.size()\n",
        "    nt, ht, wt = target.size()\n",
        "\n",
        "    # Handle inconsistent size between input and target\n",
        "    if h != ht or w != wt:\n",
        "        input = nn.functional.interpolate(input, size=(ht, wt), mode=\"bilinear\", align_corners=True)\n",
        "\n",
        "    input = input.transpose(1, 2).transpose(2, 3).contiguous().view(-1, c)\n",
        "    target = target.view(-1)\n",
        "    loss = nn.functional.cross_entropy(\n",
        "        input, target, weight=weight, size_average=size_average, ignore_index=250\n",
        "    )\n",
        "    # print('lo1 shape', loss.shape)\n",
        "    return loss\n",
        "\n",
        "# predict, groundtruth are both [batch, imsize, imsize]\n",
        "def get_miou(predict, groundtruth, num_classes=19, smoothing=1e-6):\n",
        "    pred = predict.to('cpu')\n",
        "    grdth = groundtruth.to('cpu')\n",
        "    miou_sum = 0\n",
        "    batch = predict.size()[0]\n",
        "    for idx in range(batch):\n",
        "        area_intersect_all = torch.zeros(num_classes).to('cpu')\n",
        "        area_union_all = torch.zeros(num_classes).to('cpu')\n",
        "        for cls_idx in range(num_classes):\n",
        "            area_intersect = torch.sum((pred[idx] == grdth[idx]) * (pred[idx] == cls_idx))\n",
        "            area_pred_label = torch.sum(pred[idx] == cls_idx)\n",
        "            area_gt_label = torch.sum(grdth[idx] == cls_idx)\n",
        "            area_union = area_pred_label + area_gt_label - area_intersect\n",
        "\n",
        "            area_intersect_all[cls_idx] += area_intersect + smoothing\n",
        "            area_union_all[cls_idx] += area_union + smoothing\n",
        "\n",
        "        iou_all = area_intersect_all / area_union_all * 100.0\n",
        "        miou = iou_all.mean()\n",
        "\n",
        "        miou_sum += miou\n",
        "\n",
        "    return miou_sum"
      ],
      "metadata": {
        "id": "SS1aL5SfTY7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_my_palette(impath):\n",
        "    img = Image.open(impath)\n",
        "    palette = img.getpalette()\n",
        "    return palette\n",
        "\n",
        "def put_my_palette(img, pale):\n",
        "    img = img.putpalette(pale)\n",
        "    return img\n",
        "\n",
        "# ts: [512, 512] after * 255\n",
        "def tensor2uint18(ts):\n",
        "    ts = ts.long().cpu().numpy()\n",
        "    ts = ts.astype(np.uint8)\n",
        "    return ts"
      ],
      "metadata": {
        "id": "amcsIwk9cJcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# images: [batch, 3, 512, 512], tensor\n",
        "# labels: [batch, 512, 512], tensor\n",
        "def wandb_log_image_table(images, predicted, labels, pale):\n",
        "    \"Log a wandb.Table with (img, pred, target, scores)\"\n",
        "    table = wandb.Table(columns=[\"image\", \"pred\", \"target\"])\n",
        "    images, predicted, labels = images.cpu(), predicted.cpu(), labels.cpu()\n",
        "    #my_pale =\n",
        "    for img, pred, targ in zip(images, predicted, labels):\n",
        "        # img\n",
        "        img = img.long().numpy()\n",
        "        img = np.transpose(img, (1, 2, 0))\n",
        "\n",
        "        # pred\n",
        "        pred = tensor2uint18(pred)\n",
        "        pred = Image.fromarray(pred)\n",
        "        pred.putpalette(pale)\n",
        "\n",
        "        # targ\n",
        "        targ = tensor2uint18(targ)\n",
        "        targ = Image.fromarray(targ)\n",
        "        targ.putpalette(pale)\n",
        "\n",
        "        # add_data\n",
        "        table.add_data(wandb.Image(img), wandb.Image(pred), wandb.Image(targ))\n",
        "    #wandb.log({\"predictions_table\":table}, commit=False)\n",
        "    wandb.log({\"predictions_table\":table}, commit=False)"
      ],
      "metadata": {
        "id": "5xoK4HMYDwjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, optimizer, epoch, miou, PATH):\n",
        "    torch.save({\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'epoch': epoch,\n",
        "            'miou': miou\n",
        "            }, PATH)\n",
        "# Helper function to print time\n",
        "def total_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "# def load_model(model, optimizer, PATH):\n",
        "#     checkpoint = torch.load(PATH)\n",
        "#     model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#     optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#     epoch = checkpoint['epoch']\n",
        "#     miou = checkpoint['miou']\n",
        "#     return model, optimizer, epoch, miou"
      ],
      "metadata": {
        "id": "ItlPUHGfp3cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loader"
      ],
      "metadata": {
        "id": "zlv-jyRvHKko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "    mode=\"train/val/test\"\n",
        "    img.shape: torch.Size([3, 512, 512])\n",
        "    label.shape: torch.Size([1, 512, 512])\n",
        "'''\n",
        "class FaceParse_Dataset(Dataset):\n",
        "    def __init__(self, img_path, label_path, transform_img, transform_label, mode=\"train\"):\n",
        "        self.img_path = img_path\n",
        "        self.label_path = label_path\n",
        "        self.transform_img = transform_img\n",
        "        self.transform_label = transform_label\n",
        "        self.train_dataset = []\n",
        "        self.val_dataset = []\n",
        "        self.test_dataset = []\n",
        "        self.mode = mode\n",
        "        self.preprocess()\n",
        "\n",
        "        if mode == \"train\":\n",
        "            self.num_images = len(self.train_dataset)\n",
        "        elif mode == \"val\":\n",
        "            self.num_images = len(self.val_dataset)\n",
        "        else :\n",
        "            self.num_images = len(self.test_dataset)\n",
        "\n",
        "    def preprocess(self):\n",
        "\n",
        "        for i in range(len([name for name in os.listdir(self.img_path) if os.path.isfile(os.path.join(self.img_path, name))])):\n",
        "            img_path = os.path.join(self.img_path, str(i)+'.jpg')\n",
        "            # label_path = os.path.join(self.label_path, str(i)+'.png')\n",
        "            #print (img_path, label_path)\n",
        "            if self.mode == \"train\":\n",
        "                label_path = os.path.join(self.label_path, str(i)+'.png')\n",
        "                self.train_dataset.append([img_path, label_path])\n",
        "            elif self.mode == \"val\":\n",
        "                label_path = os.path.join(self.label_path, str(i)+'.png')\n",
        "                self.val_dataset.append([img_path, label_path])\n",
        "            elif self.mode == \"test\":\n",
        "                self.test_dataset.append(img_path)\n",
        "\n",
        "        print(f'Finished preprocessing the CelebA dataset in {self.mode} mode...')\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.mode == \"test\":\n",
        "            dataset = self.test_dataset\n",
        "            img_path = dataset[index]\n",
        "            image = Image.open(img_path)\n",
        "            return self.transform_img(image)\n",
        "        else:\n",
        "            dataset = self.train_dataset if self.mode == \"train\" else self.val_dataset\n",
        "            img_path, label_path = dataset[index]\n",
        "            image = Image.open(img_path)\n",
        "            label = Image.open(label_path)\n",
        "            return self.transform_img(image), self.transform_label(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the number of images.\"\"\"\n",
        "        return self.num_images\n",
        "\n",
        "class Data_Loader():\n",
        "    def __init__(self, img_path, label_path, image_size, batch_size, mode):\n",
        "        self.img_path = img_path\n",
        "        self.label_path = label_path\n",
        "        self.imsize = image_size\n",
        "        self.batch = batch_size\n",
        "        self.mode = mode\n",
        "\n",
        "    def transform_img(self, resize, totensor, normalize, centercrop):\n",
        "        options = []\n",
        "        if centercrop:\n",
        "            options.append(T.CenterCrop(160))\n",
        "        if resize:\n",
        "            options.append(T.Resize((self.imsize,self.imsize)))\n",
        "        if totensor:\n",
        "            options.append(T.ToTensor())\n",
        "        if normalize:\n",
        "            options.append(T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)))\n",
        "        transform = T.Compose(options)\n",
        "        return transform\n",
        "\n",
        "    def transform_label(self, resize, totensor, normalize, centercrop):\n",
        "        options = []\n",
        "        if centercrop:\n",
        "            options.append(T.CenterCrop(160))\n",
        "        if resize:\n",
        "            options.append(T.Resize((self.imsize,self.imsize)))\n",
        "        if totensor:\n",
        "            options.append(T.ToTensor())\n",
        "        if normalize:\n",
        "            options.append(T.Normalize((0, 0, 0), (0, 0, 0)))\n",
        "        transform = T.Compose(options)\n",
        "        return transform\n",
        "\n",
        "    def loader(self):\n",
        "        transform_img = self.transform_img(True, True, True, False)\n",
        "        transform_label = self.transform_label(True, True, False, False)\n",
        "        dataset = FaceParse_Dataset(self.img_path, self.label_path, transform_img, transform_label, self.mode)\n",
        "\n",
        "        loader = DataLoader(dataset=dataset,\n",
        "                            batch_size=self.batch,\n",
        "                            #shuffle=True,\n",
        "                            shuffle=(self.mode==\"train\"),\n",
        "                            num_workers=2,\n",
        "                            drop_last=False)\n",
        "        return loader"
      ],
      "metadata": {
        "id": "WW5T5isdvH_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainer"
      ],
      "metadata": {
        "id": "eyFJWVzT0L5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer(object):\n",
        "    def __init__(self, model, optimizer, train_loader, val_loader, config):\n",
        "\n",
        "        self.model_version = config[\"MODEL_VERSION\"]\n",
        "        self.device = config[\"DEVICE\"]\n",
        "        self.pale = config[\"PALETTE\"]\n",
        "\n",
        "        # Data loader\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "\n",
        "        # exact model and optimizer\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "        self.num_epoch = config[\"NUM_EPOCH\"]\n",
        "        self.start_epoch = config[\"START_EPOCH\"]\n",
        "        self.num_classes = config[\"NUM_CLASSES\"]\n",
        "\n",
        "        # Save model\n",
        "        self.model_save_step = config[\"MODEL_SAVE_STEP\"]\n",
        "        self.model_save_path = config[\"MODEL_SAVE_PATH\"]\n",
        "\n",
        "        self.best_mious = config[\"BEST_MIOUS\"]\n",
        "        self.best_epochs = config[\"BEST_EPOCHS\"]\n",
        "\n",
        "        self.need_log_images = config[\"LOG_IMAGES\"]\n",
        "        self.smoothing = config[\"SMOOTHING\"]\n",
        "    #     self.build_model\n",
        "\n",
        "    # def train(self):\n",
        "    #     self.model =\n",
        "\n",
        "    def train(self):\n",
        "        for epoch in range(self.start_epoch, self.start_epoch+ self.num_epoch):\n",
        "            # print(self.model)\n",
        "            # print(self.model.type)\n",
        "            self.model.train()\n",
        "\n",
        "            train_loss = 0\n",
        "            train_miou = 0\n",
        "            train_num = 0\n",
        "\n",
        "            val_loss = 0\n",
        "            val_miou = 0\n",
        "            val_num = 0\n",
        "\n",
        "            # train\n",
        "            with tqdm(total=len(self.train_loader), desc=\"training progress bar\") as progress_bar:\n",
        "                progress_bar.set_description('Epoch: {}/{} training'.format(epoch+1, self.start_epoch+ self.num_epoch ))\n",
        "                for batch, (imgs, labels) in enumerate(self.train_loader):\n",
        "                    # imgs: [batch, 3, imsize, imsize]\n",
        "                    # labels: [batch, 1, imsize, imsize]\n",
        "                    imgs, labels = imgs.to(self.device), labels.to(self.device)\n",
        "                    #print(labels)\n",
        "\n",
        "                    # Forward\n",
        "                    # outputs: [batch, num_class, imsize, imsize]\n",
        "                    outputs = self.model(imgs)\n",
        "\n",
        "                    # *255 to restore the real pixel value (transform.ToTensor has / 255)\n",
        "                    labels[:, 0, :, :] = labels[:, 0, :, :] * 255.0\n",
        "                    # labels_real_plain: [batch, imsize, imsize]\n",
        "                    labels_real_plain = labels[:, 0, :, :]\n",
        "                    # print(labels_real_plain)\n",
        "\n",
        "                    # compute loss\n",
        "                    # print('outputs shape: ', outputs.shape)\n",
        "                    # print('labels_real_plain shape: ', labels_real_plain.long().shape)\n",
        "                    loss = cross_entropy2d(outputs, labels_real_plain.long())\n",
        "                    # print('loss shape: ', loss.shape)\n",
        "                    # print('imgs.size(0): ', imgs.size(0))\n",
        "                    # print('loss.data:', loss.data)\n",
        "                    train_loss += loss.data * imgs.size(0)\n",
        "                    # Backprop the gradient and update parameters\n",
        "                    self.optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    self.optimizer.step()\n",
        "\n",
        "                    # compute miou\n",
        "                    # pred_mask: [batch, imsize, imsize]\n",
        "                    pred_mask = torch.argmax(outputs, dim=1)\n",
        "                    train_miou += get_miou(pred_mask, labels_real_plain, num_classes=self.num_classes, smoothing=self.smoothing)\n",
        "                    # count total_num\n",
        "                    train_num += imgs.size(0)\n",
        "\n",
        "                    if(batch) % 10 == 9:\n",
        "                        progress_bar.set_postfix(batch='{}'.format(batch),\n",
        "                                                 train_miou=\"{:.2f}%\".format(train_miou / train_num),\n",
        "                                                 train_loss='{:.5f}'.format(train_loss / train_num))\n",
        "                    progress_bar.update(1)\n",
        "\n",
        "            # update wandb\n",
        "            wandb.log({\"train_loss\": (train_loss / train_num), \"train_miou\": (train_miou / train_num), \\\n",
        "                        \"epoch\": epoch+1}, step = epoch - self.start_epoch)\n",
        "            # Log validation metrics\n",
        "            # Needchange\n",
        "            val_loss, val_miou = self.valid(epoch, log_images=self.need_log_images, batch_idx=0)\n",
        "\n",
        "            wandb.log({\"val_loss\": val_loss, \"val_miou\": val_miou}, step=epoch - self.start_epoch)\n",
        "            #print(f\"Train Loss: {train_loss:.3f}, Valid Loss: {val_loss:3f}, accuracy: {accuracy:.2f}\")\n",
        "\n",
        "            # Save model based on miou\n",
        "            min_best_mious = min(self.best_mious)\n",
        "            indexof_min_best_mious = self.best_mious.index(min(self.best_mious))\n",
        "            if val_miou > min_best_mious:   # replace the model which has the min miou with current model.\n",
        "                self.best_mious[indexof_min_best_mious] = val_miou\n",
        "                self.best_epochs[indexof_min_best_mious] = epoch\n",
        "                save_model(self.model, self.optimizer, epoch+1, val_miou, \\\n",
        "                           os.path.join(self.model_save_path, '{}_MODEL{}.pth').format(indexof_min_best_mious, self.model_version))\n",
        "\n",
        "                #os.path.join(self.model_save_path, '{}_MODEL.pth'.format(epoch + 1)))\n",
        "                print(\"Saving best model at epoch {} with miou {}\".format(epoch+1, val_miou))\n",
        "            #            os.path.join(self.model_save_path, '{}_G.pth'.format(step + 1)))\n",
        "\n",
        "            # Save model based on epoch\n",
        "            #Needchange\n",
        "            if epoch % self.model_save_step == (self.model_save_step - 1):   # each 10 epochs save the model once.\n",
        "\n",
        "                save_model(self.model, self.optimizer, epoch+1, val_miou, \\\n",
        "                           os.path.join(self.model_save_path, 'FUNDAMODEL{}.pth').format(self.model_version))\n",
        "\n",
        "                #os.path.join(self.model_save_path, '{}_MODEL.pth'.format(epoch + 1)))\n",
        "                print(\"Saving fundamodel at epoch {} with miou {}\".format(epoch+1, val_miou))\n",
        "            #            os.path.join(self.model_save_path, '{}_G.pth'.format(step + 1)))\n",
        "\n",
        "        return self.best_mious ,self.best_epochs\n",
        "\n",
        "    # def load_pretrained_model(self):\n",
        "    #     self.G.load_state_dict(torch.load(os.path.join(\n",
        "    #         self.model_save_path, '{}_G.pth'.format(self.pretrained_model))))\n",
        "    #     print('loaded trained models (step: {})..!'.format(self.pretrained_model))\n",
        "\n",
        "    def valid(self, epoch, log_images=False, batch_idx=0):\n",
        "        \"Compute performance of the model on the validation dataset and log a wandb.Table\"\n",
        "        self.model.eval()\n",
        "        val_loss = 0.\n",
        "        val_miou = 0.\n",
        "        val_num = 0\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            with tqdm(total=len(val_loader), desc=\"validating progress bar\") as progress_bar:\n",
        "                progress_bar.set_description('epoch: {}/{} validating'.format(epoch+1, self.start_epoch+ self.num_epoch))\n",
        "\n",
        "                for batch, (imgs, labels) in enumerate(self.val_loader):\n",
        "                    # imgs: [batch, 3, imsize, imsize]\n",
        "                    # labels: [batch, 1, imsize, imsize]\n",
        "                    imgs, labels = imgs.to(self.device), labels.to(self.device)\n",
        "                    # outputs: [batch, num_class, imsize, imsize]\n",
        "                    outputs = self.model(imgs)\n",
        "                    # *255 to restore the real pixel value (transform.ToTensor has / 255)\n",
        "                    labels[:, 0, :, :] = labels[:, 0, :, :] * 255.0\n",
        "                    # labels_real_plain: [batch, imsize, imsize]\n",
        "                    labels_real_plain = labels[:, 0, :, :]\n",
        "                    # compute loss (average loss over one batch)\n",
        "                    loss = cross_entropy2d(outputs, labels_real_plain.long())\n",
        "                    val_loss += loss.data * imgs.size(0)\n",
        "                    # compute miou\n",
        "                    # pred_mask: [batch, imsize, imsize]\n",
        "                    pred_mask = torch.argmax(outputs, dim=1)\n",
        "                    val_miou += get_miou(pred_mask, labels_real_plain, num_classes=self.num_classes, smoothing=self.smoothing)\n",
        "                    # count val_num\n",
        "                    val_num += imgs.size(0)\n",
        "\n",
        "                    # Log one batch of images to the dashboard, always same batch_idx.\n",
        "                    # Needchange\n",
        "                    #if batch==batch_idx and log_images:\n",
        "                    if (epoch % self.model_save_step == (self.model_save_step - 1)) and batch==batch_idx and log_images:\n",
        "                        wandb_log_image_table(imgs*255, pred_mask, labels_real_plain, pale=self.pale)\n",
        "                    # update progress_bar\n",
        "                    progress_bar.set_postfix(miou=\"{:.2f}%\".format(val_miou / val_num),\n",
        "                                              loss='{:.5f}'.format(val_loss / val_num))\n",
        "                    progress_bar.update(1)\n",
        "\n",
        "        return val_loss / val_num, val_miou / val_num\n",
        "\n"
      ],
      "metadata": {
        "id": "vdesqO4u7Qm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tester"
      ],
      "metadata": {
        "id": "FPqFKSiyZQZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Tester(object):\n",
        "    def __init__(self, model, test_loader, config, suffix=\"\"):\n",
        "\n",
        "        #self.model_version = config[\"MODEL_VERSION\"]\n",
        "        self.device = config[\"DEVICE\"]\n",
        "        self.pale = config[\"PALETTE\"]\n",
        "\n",
        "        # exact model and optimizer\n",
        "        self.model = model\n",
        "        # Data loader\n",
        "        self.test_loader = test_loader\n",
        "        self.suffix = suffix\n",
        "\n",
        "        self.test_batch_size = config[\"TEST_BATCH_SIZE\"]\n",
        "        self.gray_label_path = os.path.join(config[\"RESULTS_PATH\"], 'gray{}'.format(self.suffix))\n",
        "        self.color_label_path = os.path.join(config[\"RESULTS_PATH\"], 'color{}'.format(self.suffix))\n",
        "\n",
        "        self.making_files()\n",
        "\n",
        "    def making_files(self):\n",
        "        if not os.path.exists(self.gray_label_path):\n",
        "              os.mkdir(self.gray_label_path)\n",
        "              print(\"New gray{} file!\".format(self.suffixs))\n",
        "        if not os.path.exists(self.color_label_path):\n",
        "              os.mkdir(self.color_label_path)\n",
        "              print(\"New color{} file!\".format(self.suffix))\n",
        "\n",
        "    def test(self):\n",
        "        \"Compute performance of the model on the test dataset.\"\n",
        "        self.model.eval()\n",
        "\n",
        "        # test_loss = 0.\n",
        "        # test_miou = 0.\n",
        "        test_num = 0\n",
        "        result_num = []\n",
        "\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            for batch, imgs in enumerate(self.test_loader):\n",
        "                # imgs: [batch, 3, imsize, imsize]\n",
        "                # labels: [batch, 1, imsize, imsize]\n",
        "                imgs = imgs.to(self.device)\n",
        "                # outputs: [batch, num_class, imsize, imsize]\n",
        "                outputs = self.model(imgs)\n",
        "                # *255 to restore the real pixel value (transform.ToTensor has / 255)\n",
        "                # labels[:, 0, :, :] = labels[:, 0, :, :] * 255.0\n",
        "                # labels_real_plain: [batch, imsize, imsize]\n",
        "                # labels_real_plain = labels[:, 0, :, :]\n",
        "                # compute loss (average loss over one batch)\n",
        "                # loss = cross_entropy2d(outputs, labels_real_plain.long())\n",
        "                # test_loss += loss.data * imgs.size(0)\n",
        "                # compute miou\n",
        "                # pred_mask_tensor: [batch, imsize, imsize]\n",
        "                pred_mask_tensor = torch.argmax(outputs, dim=1)\n",
        "                pred_mask_numpy = pred_mask_tensor.cpu().numpy()\n",
        "                # test_miou += get_miou(pred_mask, labels_real_plain, num_classes=self.num_classes)\n",
        "                # print(\"size: \", pred_mask_tensor.shape)\n",
        "                for k in range(imgs.size(0)):\n",
        "                    # gray_piciture\n",
        "                    cv2.imwrite(os.path.join(self.gray_label_path, str(test_num + k) +'.png'), pred_mask_numpy[k])\n",
        "                    # print(\"Gray pic {}.png\".format(test_num + k))\n",
        "\n",
        "                    # color_picture\n",
        "                    color_label = tensor2uint18(pred_mask_tensor[k])\n",
        "                    color_label = Image.fromarray(color_label)\n",
        "                    color_label.putpalette(self.pale)\n",
        "                    color_label.save(os.path.join(self.color_label_path, str(test_num + k) +'.png'))\n",
        "\n",
        "                    result_num.append(test_num + k)\n",
        "                    # print(\"Color pic {}.png\".format(test_num + k))\n",
        "                    #cv2.imwrite(os.path.join(self.gray_label_path, str(test_num + k) +'.png'), pred_mask[k])\n",
        "\n",
        "                # count test_num\n",
        "                test_num += imgs.size(0)\n",
        "``\n",
        "\n",
        "        print(\"Testing {} results has completed!\".format(test_num))\n",
        "        return result_num\n",
        "        # return test_loss / test_num, test_miou / test_num\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7r9WI2mffsie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameters"
      ],
      "metadata": {
        "id": "Q83rGpkkvMet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Parameters = {\n",
        "    \"MODEL_VERSION\": '2.1',\n",
        "    \"MODEL_LOAD_VERSION\": '2.1',\n",
        "    \"DEVICE\": DEVICE,\n",
        "\n",
        "    # Needchange\n",
        "    \"NUM_EPOCH\": 40,\n",
        "    \"START_EPOCH\": 0,\n",
        "    \"NUM_CLASSES\": 19,\n",
        "    \"IMSIZE\": 512,\n",
        "    \"TRAIN_BATCH_SIZE\": 16,    # input batch size for training (default: 64)\n",
        "    \"VAL_BATCH_SIZE\": 64,    # input batch size for testing (default: 1000)\n",
        "    \"TEST_BATCH_SIZE\": 64,\n",
        "    #\"TRAIN_EPOCHS\": 51,        # number of epochs to train (default: 10)\n",
        "    #\"SEED\": 42,               # random seed (default: 42)\n",
        "\n",
        "    # Model Para\n",
        "    \"LEARNING_RATE\": 1e-4 ,   # learning rate (default: 0.01)\n",
        "    \"LR_DECAY\": 0.95,\n",
        "    \"BETA1\": 0.5,\n",
        "    \"BETA2\": 0.999,\n",
        "\n",
        "    # Path\n",
        "    \"TRAIN_PATH\": os.path.join(ROOT, 'train'),\n",
        "    \"VAL_PATH\": os.path.join(ROOT, 'val'),\n",
        "    \"TEST_PATH\": os.path.join(ROOT, 'test'),\n",
        "    \"RESULTS_PATH\": os.path.join(ROOT, 'results'),\n",
        "\n",
        "    # Save\n",
        "    \"MODEL_SAVE_STEP\": 5,\n",
        "    \"MODEL_SAVE_PATH\": os.path.join(ROOT, 'models'),\n",
        "\n",
        "    # Load\n",
        "    \"MODEL_IF_LOAD\": False,\n",
        "    \"MODEL_LOAD_PATH\": os.path.join(ROOT, 'models'),\n",
        "\n",
        "    # Best model\n",
        "    # \"BEST_MIOUS\": 5*[0],\n",
        "    # \"BEST_EPOCHS\": 5*[0],\n",
        "    \"EXPECTED_MODEL_NUMBER\": 4,\n",
        "\n",
        "    \"LOG_IMAGES\": False,\n",
        "    \"SMOOTHING\": 1e-6,\n",
        "}\n",
        "\n",
        "Parameters[\"BEST_MIOUS\"] = Parameters[\"EXPECTED_MODEL_NUMBER\"] * [0]\n",
        "Parameters[\"BEST_EPOCHS\"] = Parameters[\"EXPECTED_MODEL_NUMBER\"] * [0]\n",
        "# get palette\n",
        "Parameters[\"PALETTE\"] = get_my_palette(os.path.join(Parameters[\"TRAIN_PATH\"], 'train_mask/1.png'))\n",
        "# # Define model and optimizer\n",
        "# Parameters[\"MODEL\"] = smp.Unet(\n",
        "#         encoder_name=\"resnet34\",\n",
        "#         encoder_weights=\"imagenet\",\n",
        "#         in_channels=3,\n",
        "#         classes=Parameters[\"NUM_CLASSES\"],\n",
        "#     ).to(Parameters[\"DEVICE\"])\n",
        "\n",
        "# Parameters[\"OPTIMIZER\"] = torch.optim.Adam(filter(lambda p: p.requires_grad, Parameters[\"MODEL\"].parameters()), \\\n",
        "#                               Parameters[\"LEARNING_RATE\"], [Parameters[\"BETA1\"], Parameters[\"BETA2\"]])"
      ],
      "metadata": {
        "id": "qrHqHvBY9wic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_path = os.path.join(Parameters[\"TRAIN_PATH\"], 'train_image')\n",
        "train_label_path = os.path.join(Parameters[\"TRAIN_PATH\"], 'train_mask')\n",
        "val_img_path = os.path.join(Parameters[\"VAL_PATH\"], 'val_image')\n",
        "val_label_path = os.path.join(Parameters[\"VAL_PATH\"], 'val_mask')\n",
        "test_img_path = os.path.join(Parameters[\"TEST_PATH\"], 'test_image')"
      ],
      "metadata": {
        "id": "CjJ-JY_iHNWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_img_path = os.path.join(Parameters[\"TRAIN_PATH\"], 'train_image')\n",
        "# train_label_path = os.path.join(Parameters[\"TRAIN_PATH\"], 'train_mask')\n",
        "# val_img_path = os.path.join(Parameters[\"VAL_PATH\"], 'val_image')\n",
        "# val_label_path = os.path.join(Parameters[\"VAL_PATH\"], 'val_mask')\n",
        "# test_img_path = os.path.join(Parameters[\"TEST_PATH\"], 'test_image')\n",
        "\n",
        "# train_loader: img([8, 3, 512, 512]), label([8, 1, 512, 512])\n",
        "train_loader = Data_Loader(train_img_path, train_label_path, \\\n",
        "              Parameters[\"IMSIZE\"], Parameters[\"TRAIN_BATCH_SIZE\"], \"train\").loader()\n",
        "val_loader = Data_Loader(val_img_path, val_label_path, \\\n",
        "              Parameters[\"IMSIZE\"], Parameters[\"VAL_BATCH_SIZE\"], \"val\").loader()\n",
        "test_loader = Data_Loader(test_img_path, None, \\\n",
        "              Parameters[\"IMSIZE\"], Parameters[\"TEST_BATCH_SIZE\"], \"test\").loader()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2skOLdITxM1w",
        "outputId": "39fc05f8-8afa-4e7d-a6bd-e8cfa96c8a92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished preprocessing the CelebA dataset in train mode...\n",
            "Finished preprocessing the CelebA dataset in val mode...\n",
            "Finished preprocessing the CelebA dataset in test mode...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "nQDd2jF-n45J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print()\n",
        "# print(\"loaded_best_mious: \" + str(Parameters[\"BEST_MIOUS\"]))\n",
        "# print(\"loaded_best_epochs: \" + str(Parameters[\"BEST_EPOCHS\"]))\n"
      ],
      "metadata": {
        "id": "Rs2_ddJMj4f1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with wandb.init(\n",
        "    # config = Parameters,\n",
        "    project=\"Face_Parsing\"+ Parameters[\"MODEL_VERSION\"],\n",
        "    ):\n",
        "    # config = wandb.config\n",
        "\n",
        "    # Define model and optimizer\n",
        "    model = smp.Unet(\n",
        "            encoder_name=\"resnet34\",\n",
        "            encoder_weights=\"imagenet\",\n",
        "            in_channels=3,\n",
        "            classes=Parameters[\"NUM_CLASSES\"],\n",
        "        ).to(Parameters[\"DEVICE\"])\n",
        "\n",
        "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), \\\n",
        "                                 Parameters[\"LEARNING_RATE\"], [Parameters[\"BETA1\"], Parameters[\"BETA2\"]])\n",
        "    start_time = time.time()\n",
        "\n",
        "    # if need, load the paramters of the model\n",
        "    if (Parameters[\"MODEL_IF_LOAD\"]):\n",
        "        # update stored best_mious and best_epochs\n",
        "        num = Parameters[\"EXPECTED_MODEL_NUMBER\"]\n",
        "        b_mious, b_epochs = [], []\n",
        "        for i in range(num):\n",
        "            PATH = os.path.join(Parameters[\"MODEL_LOAD_PATH\"], \\\n",
        "                                                  \"{}_MODEL{}.pth\".format(i, Parameters[\"MODEL_LOAD_VERSION\"]))\n",
        "            checkpoint = torch.load(PATH)\n",
        "            # loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            b_epochs.append(checkpoint['epoch'])\n",
        "            b_mious.append(checkpoint['miou'])\n",
        "        Parameters[\"BEST_MIOUS\"] = b_mious\n",
        "        Parameters[\"BEST_EPOCHS\"] = b_epochs\n",
        "\n",
        "        print()\n",
        "        print(\"loaded_best_mious: \" + str(Parameters[\"BEST_MIOUS\"]))\n",
        "        print(\"loaded_best_epochs: \" + str(Parameters[\"BEST_EPOCHS\"]))\n",
        "\n",
        "        # really load the model and optimizer\n",
        "        LOAD_PATH = os.path.join(Parameters[\"MODEL_LOAD_PATH\"], \\\n",
        "                                             \"FUNDAMODEL{}.pth\".format(Parameters[\"MODEL_LOAD_VERSION\"]))\n",
        "        load_checkpoint = torch.load(LOAD_PATH)\n",
        "        model.load_state_dict(load_checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(load_checkpoint['optimizer_state_dict'])\n",
        "        Parameters[\"START_EPOCH\"] = load_checkpoint['epoch']\n",
        "        print()\n",
        "        print('Now the model is at epoch {} with miou {}.'.format(load_checkpoint['epoch'], load_checkpoint['miou']))\n",
        "        # epoch = checkpoint['epoch']\n",
        "        # miou = checkpoint['miou']\n",
        "        # Parameters[\"BEST_EPOCH\"] = checkpoint['epoch']\n",
        "        # Parameters[\"BEST_MIOU\"] = checkpoint['miou']\n",
        "\n",
        "\n",
        "    trainer = Trainer(model, optimizer, train_loader, val_loader, Parameters)\n",
        "    result_best_mious, result_best_epochs = trainer.train()\n",
        "    print()\n",
        "    print(\"best_mious: \" + str(result_best_mious))\n",
        "    print(\"best_epochs: \" + str(result_best_epochs))\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = total_time(start_time, end_time)\n",
        "    print()\n",
        "    print(f'Total Time: {epoch_mins}m {epoch_secs}s')\n",
        "    #trainer = Trainer(data_loader.loader(), config)\n",
        "    #trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3452345dff754d3e8ba6fe31675272f6",
            "ff93615895714479b6b044ef66a08b73",
            "52b8a66fd8034805a5e2e66f3da42f0d",
            "210bc359f4e8457fa8f49d700322cda7",
            "1e46c9b7141d42a88c278b6f1009a343",
            "4b9d045c4ccf40f3937d2b0c14c0cf9e",
            "5b8ef82de1bd450bb311792025a75da8",
            "9edb9b3fb429489590377be30ade89ca",
            "38175f951075450cad17e5f856eede78",
            "5133565d83a449df8a25e6281655aa5c",
            "c0627c483191408caa378712fab149eb",
            "3b5aeb77d2f04207a206a09ff37ee6a0",
            "4bd1296e69ea4b95bebc93b73fcb3367",
            "93d42be650ed4944ac5dd43568b88eea",
            "bb0f528f504d43ebaee5907f66cfb9a5",
            "7dae0e11aaae40538823d441cb3b0b35",
            "597c7526b38a49ebb2a212330914f383",
            "49832372043942d5a821c6e057749438",
            "95e3d8d857bb4f2c815af1a8ea390b2a"
          ]
        },
        "id": "EcZFdsci-mQO",
        "outputId": "551b7fb3-e8eb-49ab-83af-20ff05ac346e"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220322_221907-379oriys</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/skywalk3r/Face_Parsing2.1/runs/379oriys\" target=\"_blank\">wobbly-wildflower-1</a></strong> to <a href=\"https://wandb.ai/skywalk3r/Face_Parsing2.1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3452345dff754d3e8ba6fe31675272f6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/83.3M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 1/40 training:   0%|          | 0/313 [00:00<?, ?it/s] /usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "Epoch: 1/40 training: 100%|██████████| 313/313 [22:13<00:00,  4.26s/it, batch=309, train_loss=1.05495, train_miou=25.88%]\n",
            "epoch: 1/40 validating: 100%|██████████| 16/16 [05:35<00:00, 20.94s/it, loss=0.52818, miou=42.29%]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving best model at epoch 1 with miou 42.28943634033203\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 2/40 training: 100%|██████████| 313/313 [11:21<00:00,  2.18s/it, batch=309, train_loss=0.40489, train_miou=46.83%]\n",
            "epoch: 2/40 validating: 100%|██████████| 16/16 [01:17<00:00,  4.86s/it, loss=0.32179, miou=50.13%]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving best model at epoch 2 with miou 50.131507873535156\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 3/40 training: 100%|██████████| 313/313 [11:21<00:00,  2.18s/it, batch=309, train_loss=0.27751, train_miou=54.08%]\n",
            "epoch: 3/40 validating: 100%|██████████| 16/16 [01:17<00:00,  4.84s/it, loss=0.26044, miou=58.29%]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving best model at epoch 3 with miou 58.29265213012695\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 4/40 training: 100%|██████████| 313/313 [11:22<00:00,  2.18s/it, batch=309, train_loss=0.21559, train_miou=62.18%]\n",
            "epoch: 4/40 validating: 100%|██████████| 16/16 [01:17<00:00,  4.84s/it, loss=0.26879, miou=64.48%]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving best model at epoch 4 with miou 64.47606658935547\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 5/40 training: 100%|██████████| 313/313 [11:23<00:00,  2.18s/it, batch=309, train_loss=0.18069, train_miou=74.05%]\n",
            "epoch: 5/40 validating: 100%|██████████| 16/16 [01:17<00:00,  4.84s/it, loss=0.21934, miou=75.57%]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving best model at epoch 5 with miou 75.5713119506836\n",
            "Saving fundamodel at epoch 5 with miou 75.5713119506836\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 6/40 training: 100%|██████████| 313/313 [11:26<00:00,  2.19s/it, batch=309, train_loss=0.15404, train_miou=78.21%]\n",
            "epoch: 6/40 validating: 100%|██████████| 16/16 [01:18<00:00,  4.89s/it, loss=0.19819, miou=80.39%]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving best model at epoch 6 with miou 80.39286804199219\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 7/40 training: 100%|██████████| 313/313 [11:26<00:00,  2.19s/it, batch=309, train_loss=0.12972, train_miou=82.49%]\n",
            "epoch: 7/40 validating: 100%|██████████| 16/16 [01:17<00:00,  4.83s/it, loss=0.19293, miou=80.12%]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving best model at epoch 7 with miou 80.11579132080078\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 8/40 training: 100%|██████████| 313/313 [11:27<00:00,  2.20s/it, batch=309, train_loss=0.11758, train_miou=83.19%]\n",
            "epoch: 8/40 validating: 100%|██████████| 16/16 [01:18<00:00,  4.90s/it, loss=0.18888, miou=80.20%]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving best model at epoch 8 with miou 80.19844818115234\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 9/40 training: 100%|██████████| 313/313 [11:28<00:00,  2.20s/it, batch=309, train_loss=0.11068, train_miou=83.58%]\n",
            "epoch: 9/40 validating: 100%|██████████| 16/16 [01:19<00:00,  4.95s/it, loss=0.22134, miou=78.47%]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving best model at epoch 9 with miou 78.46834564208984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 10/40 training: 100%|██████████| 313/313 [11:28<00:00,  2.20s/it, batch=309, train_loss=0.10607, train_miou=83.85%]\n",
            "epoch: 10/40 validating: 100%|██████████| 16/16 [01:18<00:00,  4.90s/it, loss=0.18700, miou=81.04%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model at epoch 10 with miou 81.04246520996094\n",
            "Saving fundamodel at epoch 10 with miou 81.04246520996094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 11/40 training: 100%|██████████| 313/313 [11:27<00:00,  2.20s/it, batch=309, train_loss=0.09843, train_miou=84.45%]\n",
            "epoch: 11/40 validating: 100%|██████████| 16/16 [01:18<00:00,  4.90s/it, loss=0.18861, miou=81.65%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model at epoch 11 with miou 81.64600372314453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 12/40 training: 100%|██████████| 313/313 [11:27<00:00,  2.20s/it, batch=309, train_loss=0.08900, train_miou=85.07%]\n",
            "epoch: 12/40 validating: 100%|██████████| 16/16 [01:18<00:00,  4.91s/it, loss=0.18538, miou=81.74%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model at epoch 12 with miou 81.7380599975586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 13/40 training: 100%|██████████| 313/313 [11:27<00:00,  2.20s/it, batch=309, train_loss=0.08149, train_miou=85.63%]\n",
            "epoch: 13/40 validating: 100%|██████████| 16/16 [01:18<00:00,  4.92s/it, loss=0.19407, miou=81.83%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model at epoch 13 with miou 81.82854461669922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 14/40 training: 100%|██████████| 313/313 [11:27<00:00,  2.20s/it, batch=309, train_loss=0.07893, train_miou=85.91%]\n",
            "epoch: 14/40 validating: 100%|██████████| 16/16 [01:17<00:00,  4.85s/it, loss=0.19546, miou=82.19%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model at epoch 14 with miou 82.19269561767578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 15/40 training: 100%|██████████| 313/313 [11:28<00:00,  2.20s/it, batch=309, train_loss=0.07589, train_miou=86.26%]\n",
            "epoch: 15/40 validating: 100%|██████████| 16/16 [01:19<00:00,  4.94s/it, loss=0.19474, miou=81.66%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model at epoch 15 with miou 81.65592193603516\n",
            "Saving fundamodel at epoch 15 with miou 81.65592193603516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 16/40 training: 100%|██████████| 313/313 [11:29<00:00,  2.20s/it, batch=309, train_loss=0.07355, train_miou=86.40%]\n",
            "epoch: 16/40 validating: 100%|██████████| 16/16 [01:19<00:00,  4.94s/it, loss=0.25363, miou=78.12%]\n",
            "Epoch: 17/40 training: 100%|██████████| 313/313 [11:28<00:00,  2.20s/it, batch=309, train_loss=0.10561, train_miou=84.10%]\n",
            "epoch: 17/40 validating: 100%|██████████| 16/16 [01:18<00:00,  4.92s/it, loss=0.19998, miou=81.52%]\n",
            "Epoch: 18/40 training: 100%|██████████| 313/313 [11:28<00:00,  2.20s/it, batch=309, train_loss=0.08466, train_miou=85.57%]\n",
            "epoch: 18/40 validating: 100%|██████████| 16/16 [01:18<00:00,  4.92s/it, loss=0.19217, miou=81.43%]\n",
            "Epoch: 19/40 training: 100%|██████████| 313/313 [11:28<00:00,  2.20s/it, batch=309, train_loss=0.07275, train_miou=86.54%]\n",
            "epoch: 19/40 validating: 100%|██████████| 16/16 [01:18<00:00,  4.92s/it, loss=0.19596, miou=82.01%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model at epoch 19 with miou 82.01239776611328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 20/40 training: 100%|██████████| 313/313 [11:29<00:00,  2.20s/it, batch=309, train_loss=0.06403, train_miou=87.39%]\n",
            "epoch: 20/40 validating: 100%|██████████| 16/16 [01:18<00:00,  4.92s/it, loss=0.20394, miou=82.32%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model at epoch 20 with miou 82.32148742675781\n",
            "Saving fundamodel at epoch 20 with miou 82.32148742675781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 21/40 training: 100%|██████████| 313/313 [11:32<00:00,  2.21s/it, batch=309, train_loss=0.06016, train_miou=87.91%]\n",
            "epoch: 21/40 validating: 100%|██████████| 16/16 [01:19<00:00,  4.97s/it, loss=0.21211, miou=82.11%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model at epoch 21 with miou 82.11048889160156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 22/40 training: 100%|██████████| 313/313 [11:31<00:00,  2.21s/it, batch=309, train_loss=0.05801, train_miou=88.15%]\n",
            "epoch: 22/40 validating: 100%|██████████| 16/16 [01:18<00:00,  4.92s/it, loss=0.21528, miou=82.23%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model at epoch 22 with miou 82.22952270507812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 23/40 training: 100%|██████████| 313/313 [11:29<00:00,  2.20s/it, batch=309, train_loss=0.05641, train_miou=88.45%]\n",
            "epoch: 23/40 validating: 100%|██████████| 16/16 [01:18<00:00,  4.92s/it, loss=0.21613, miou=82.34%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model at epoch 23 with miou 82.33822631835938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 24/40 training: 100%|██████████| 313/313 [11:28<00:00,  2.20s/it, batch=309, train_loss=0.05540, train_miou=88.51%]\n",
            "epoch: 24/40 validating: 100%|██████████| 16/16 [01:18<00:00,  4.92s/it, loss=0.21893, miou=82.17%]\n",
            "Epoch: 25/40 training: 100%|██████████| 313/313 [11:27<00:00,  2.20s/it, batch=309, train_loss=0.05377, train_miou=88.77%]\n",
            "epoch: 25/40 validating: 100%|██████████| 16/16 [01:18<00:00,  4.91s/it, loss=0.22157, miou=82.25%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model at epoch 25 with miou 82.25031280517578\n",
            "Saving fundamodel at epoch 25 with miou 82.25031280517578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 26/40 training: 100%|██████████| 313/313 [11:29<00:00,  2.20s/it, batch=309, train_loss=0.05241, train_miou=88.97%]\n",
            "epoch: 26/40 validating: 100%|██████████| 16/16 [01:18<00:00,  4.92s/it, loss=0.22162, miou=82.40%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model at epoch 26 with miou 82.39541625976562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 27/40 training: 100%|██████████| 313/313 [11:28<00:00,  2.20s/it, batch=309, train_loss=0.05067, train_miou=89.20%]\n",
            "epoch: 27/40 validating: 100%|██████████| 16/16 [01:18<00:00,  4.88s/it, loss=0.23083, miou=81.81%]\n",
            "Epoch: 28/40 training: 100%|██████████| 313/313 [11:26<00:00,  2.19s/it, batch=309, train_loss=0.04957, train_miou=89.41%]\n",
            "epoch: 28/40 validating: 100%|██████████| 16/16 [01:18<00:00,  4.89s/it, loss=0.23518, miou=82.23%]\n",
            "Epoch: 29/40 training: 100%|██████████| 313/313 [11:25<00:00,  2.19s/it, batch=309, train_loss=0.04887, train_miou=89.48%]\n",
            "epoch: 29/40 validating: 100%|██████████| 16/16 [01:18<00:00,  4.89s/it, loss=0.22694, miou=81.94%]\n",
            "Epoch: 30/40 training: 100%|██████████| 313/313 [11:26<00:00,  2.19s/it, batch=309, train_loss=0.04754, train_miou=89.70%]\n",
            "epoch: 30/40 validating: 100%|██████████| 16/16 [01:18<00:00,  4.92s/it, loss=0.24313, miou=81.11%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving fundamodel at epoch 30 with miou 81.11105346679688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 31/40 training: 100%|██████████| 313/313 [11:29<00:00,  2.20s/it, batch=309, train_loss=0.04685, train_miou=89.82%]\n",
            "epoch: 31/40 validating: 100%|██████████| 16/16 [01:18<00:00,  4.94s/it, loss=0.23907, miou=82.14%]\n",
            "Epoch: 32/40 training: 100%|██████████| 313/313 [11:27<00:00,  2.20s/it, batch=309, train_loss=0.04452, train_miou=90.23%]\n",
            "epoch: 32/40 validating: 100%|██████████| 16/16 [01:18<00:00,  4.93s/it, loss=0.24082, miou=81.84%]\n",
            "Epoch: 33/40 training: 100%|██████████| 313/313 [11:27<00:00,  2.20s/it, batch=309, train_loss=0.04304, train_miou=90.50%]\n",
            "epoch: 33/40 validating: 100%|██████████| 16/16 [01:18<00:00,  4.91s/it, loss=0.23989, miou=81.67%]\n",
            "Epoch: 34/40 training: 100%|██████████| 313/313 [11:28<00:00,  2.20s/it, batch=309, train_loss=0.10038, train_miou=85.28%]\n",
            "epoch: 34/40 validating: 100%|██████████| 16/16 [01:18<00:00,  4.93s/it, loss=0.23356, miou=78.26%]\n",
            "Epoch: 35/40 training: 100%|██████████| 313/313 [11:27<00:00,  2.20s/it, batch=309, train_loss=0.05857, train_miou=88.27%]\n",
            "epoch: 35/40 validating: 100%|██████████| 16/16 [01:18<00:00,  4.93s/it, loss=0.24038, miou=80.67%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving fundamodel at epoch 35 with miou 80.66626739501953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 36/40 training: 100%|██████████| 313/313 [11:27<00:00,  2.20s/it, batch=309, train_loss=0.04670, train_miou=89.76%]\n",
            "epoch: 36/40 validating: 100%|██████████| 16/16 [01:18<00:00,  4.91s/it, loss=0.22972, miou=82.11%]\n",
            "Epoch: 37/40 training: 100%|██████████| 313/313 [11:27<00:00,  2.20s/it, batch=309, train_loss=0.04012, train_miou=90.74%]\n",
            "epoch: 37/40 validating: 100%|██████████| 16/16 [01:18<00:00,  4.91s/it, loss=0.23644, miou=81.73%]\n",
            "Epoch: 38/40 training: 100%|██████████| 313/313 [11:27<00:00,  2.20s/it, batch=309, train_loss=0.03782, train_miou=91.08%]\n",
            "epoch: 38/40 validating: 100%|██████████| 16/16 [01:18<00:00,  4.93s/it, loss=0.24661, miou=81.86%]\n",
            "Epoch: 39/40 training: 100%|██████████| 313/313 [11:27<00:00,  2.20s/it, batch=309, train_loss=0.03688, train_miou=91.24%]\n",
            "epoch: 39/40 validating: 100%|██████████| 16/16 [01:18<00:00,  4.91s/it, loss=0.25269, miou=81.86%]\n",
            "Epoch: 40/40 training: 100%|██████████| 313/313 [11:27<00:00,  2.20s/it, batch=309, train_loss=0.03630, train_miou=91.46%]\n",
            "epoch: 40/40 validating: 100%|██████████| 16/16 [01:18<00:00,  4.91s/it, loss=0.25383, miou=82.07%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving fundamodel at epoch 40 with miou 82.07185363769531\n",
            "\n",
            "best_mious: [tensor(82.2503), tensor(82.3382), tensor(82.3954), tensor(82.3215)]\n",
            "best_epochs: [24, 22, 25, 19]\n",
            "\n",
            "Total Time: 526m 17s\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b5aeb77d2f04207a206a09ff37ee6a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_miou</td><td>▁▃▄▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████▇██████</td></tr><tr><td>val_loss</td><td>█▄▃▃▂▁▁▁▂▁▁▁▁▁▁▂▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>val_miou</td><td>▁▂▄▅▇███▇██████▇█████████████████▇██████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>40</td></tr><tr><td>train_loss</td><td>0.0363</td></tr><tr><td>train_miou</td><td>91.46214</td></tr><tr><td>val_loss</td><td>0.25383</td></tr><tr><td>val_miou</td><td>82.07185</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">wobbly-wildflower-1</strong>: <a href=\"https://wandb.ai/skywalk3r/Face_Parsing2.1/runs/379oriys\" target=\"_blank\">https://wandb.ai/skywalk3r/Face_Parsing2.1/runs/379oriys</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220322_221907-379oriys/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Parameters[\"BEST_EPOCHS\"])\n",
        "print(Parameters['BEST_MIOUS'])"
      ],
      "metadata": {
        "id": "YxSGUL8_5tr9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5318b0a7-5a0e-4f57-b6b6-113d7cfc190c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[24, 22, 25, 19]\n",
            "[tensor(82.2503), tensor(82.3382), tensor(82.3954), tensor(82.3215)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "iKE-AO41PMtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model and optimizer\n",
        "loaded_model = smp.Unet(\n",
        "        encoder_name=\"resnet34\",\n",
        "        encoder_weights=\"imagenet\",\n",
        "        in_channels=3,\n",
        "        classes=Parameters[\"NUM_CLASSES\"],\n",
        "    ).to(Parameters[\"DEVICE\"])\n",
        "\n",
        "\n",
        "epochs, mious = [], []\n",
        "num = Parameters[\"EXPECTED_MODEL_NUMBER\"]\n",
        "for i in range(num):\n",
        "    PATH = os.path.join(Parameters[\"MODEL_LOAD_PATH\"], \\\n",
        "                                          \"{}_MODEL{}.pth\".format(i, Parameters[\"MODEL_LOAD_VERSION\"]))\n",
        "    checkpoint = torch.load(PATH)\n",
        "    # loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    epochs.append(checkpoint['epoch'])\n",
        "    mious.append(checkpoint['miou'])\n",
        "print('best_epochs: ' + str(epochs))\n",
        "print('best_mious: ' + str(mious))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n84scWYI4VP8",
        "outputId": "86763a30-3f71-4ade-ac18-98d7696c0e4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_epochs: [25, 23, 26, 20]\n",
            "best_mious: [tensor(82.2503), tensor(82.3382), tensor(82.3954), tensor(82.3215)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(Parameters[\"EXPECTED_MODEL_NUMBER\"]):\n",
        "\n",
        "    gray_label_path = os.path.join(Parameters[\"RESULTS_PATH\"], 'gray{}'.format(i))\n",
        "    color_label_path = os.path.join(Parameters[\"RESULTS_PATH\"], 'color{}'.format(i))\n",
        "    if not os.path.exists(gray_label_path):\n",
        "          os.mkdir(gray_label_path)\n",
        "          print(\"New gray{} file!\".format(i))\n",
        "    if not os.path.exists(color_label_path):\n",
        "          os.mkdir(color_label_path)\n",
        "          print(\"New color{} file!\".format(i))\n",
        "\n",
        "    LOAD_PATH = os.path.join(Parameters[\"MODEL_LOAD_PATH\"], \\\n",
        "                                          \"{}_MODEL{}.pth\".format(i, Parameters[\"MODEL_LOAD_VERSION\"]))\n",
        "    load_checkpoint = torch.load(LOAD_PATH)\n",
        "    loaded_model.load_state_dict(load_checkpoint['model_state_dict'])\n",
        "    loaded_epoch = load_checkpoint['epoch']\n",
        "    loaded_miou = load_checkpoint['miou']\n",
        "    print('loaded_epoch: ' + str(loaded_epoch))\n",
        "    print('loaded_miou: ' + str(loaded_miou))\n",
        "\n",
        "\n",
        "    tester = Tester(loaded_model, test_loader, Parameters, i)\n",
        "    result_list = tester.test()\n",
        "\n",
        "    result_file = open(os.path.join(Parameters[\"RESULTS_PATH\"], 'result_number_{}.txt'.format(i)),'w+')\n",
        "    result_file.write('total_number: ' + str(len(result_list)))\n",
        "    result_file.write('\\n')\n",
        "    result_file.write(str(result_list))\n",
        "    result_file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_x6QzpErBq78",
        "outputId": "4a2ba7bd-6ab2-4fbf-88f0-7ae70e1a8476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New gray0 file!\n",
            "New color0 file!\n",
            "loaded_epoch: 25\n",
            "loaded_miou: tensor(82.2503)\n",
            "Testing 1000 results has completed!\n",
            "New gray1 file!\n",
            "New color1 file!\n",
            "loaded_epoch: 23\n",
            "loaded_miou: tensor(82.3382)\n",
            "Testing 1000 results has completed!\n",
            "New gray2 file!\n",
            "New color2 file!\n",
            "loaded_epoch: 26\n",
            "loaded_miou: tensor(82.3954)\n",
            "Testing 1000 results has completed!\n",
            "New gray3 file!\n",
            "New color3 file!\n",
            "loaded_epoch: 20\n",
            "loaded_miou: tensor(82.3215)\n",
            "Testing 1000 results has completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# result_file = open(os.path.join(Parameters[\"RESULTS_PATH\"], 'result_number.txt'),'w+')\n",
        "# result_file.write('total_number: ' + str(len(result_list)))\n",
        "# result_file.write('\\n')\n",
        "# result_file.write(str(result_list))\n",
        "# result_file.close()"
      ],
      "metadata": {
        "id": "QGrtEWfYfOc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gray_label_path = os.path.join(Parameters[\"RESULTS_PATH\"], 'gray{}'.format(\"_New\"))\n",
        "color_label_path = os.path.join(Parameters[\"RESULTS_PATH\"], 'color{}'.format(\"_New\"))\n",
        "if not os.path.exists(gray_label_path):\n",
        "      os.mkdir(gray_label_path)\n",
        "      print(\"New gray{} file!\".format(\"_New\"))\n",
        "if not os.path.exists(color_label_path):\n",
        "      os.mkdir(color_label_path)\n",
        "      print(\"New color{} file!\".format(\"_New\"))\n",
        "\n",
        "LOAD_PATH = os.path.join(Parameters[\"MODEL_LOAD_PATH\"], \\\n",
        "                                      \"FUNDAMODEL{}.pth\".format(Parameters[\"MODEL_LOAD_VERSION\"]))\n",
        "load_checkpoint = torch.load(LOAD_PATH)\n",
        "loaded_model.load_state_dict(load_checkpoint['model_state_dict'])\n",
        "loaded_epoch = load_checkpoint['epoch']\n",
        "loaded_miou = load_checkpoint['miou']\n",
        "print('loaded_epoch: ' + str(loaded_epoch))\n",
        "print('loaded_miou: ' + str(loaded_miou))\n",
        "\n",
        "\n",
        "tester = Tester(loaded_model, test_loader, Parameters, '_New')\n",
        "result_list = tester.test()\n",
        "\n",
        "result_file = open(os.path.join(Parameters[\"RESULTS_PATH\"], 'result_number_{}.txt'.format(\"New\")),'w+')\n",
        "result_file.write('total_number: ' + str(len(result_list)))\n",
        "result_file.write('\\n')\n",
        "result_file.write(str(result_list))\n",
        "result_file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugVmbC-OzQnw",
        "outputId": "06414b09-d05f-4599-e740-9cbb65ce6bdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded_epoch: 40\n",
            "loaded_miou: tensor(82.0719)\n",
            "Testing 1000 results has completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pt1 = Parameters[\"RESULTS_PATH\"]\n",
        "print(pt1)\n",
        "files = os.listdir(pt1)\n",
        "print(files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kPWpEqF4Kz7",
        "outputId": "3689479a-626e-4244-ce8f-15ccb2abcaaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive/MyDrive/ACV/Project1/results\n",
            "['gray', 'color', 'result_number.txt', 'gray0', 'color0', 'result_number_0.txt', 'gray1', 'color1', 'result_number_1.txt', 'gray2', 'color2', 'result_number_2.txt', 'gray3', 'color3', 'gray_New', 'color_New', 'result_number__New.txt', 'result_number_4.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_para = sum(p.numel() for p in loaded_model.parameters() if p.requires_grad)\n",
        "print(\"Total Parameters: \", str(num_para))\n",
        "# 24438979"
      ],
      "metadata": {
        "id": "CP2gAeiA4cQ4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}